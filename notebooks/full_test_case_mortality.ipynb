{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Case Mortality\n",
    "\n",
    "Creating a random set of fictitious patients to show how the code works without using patient data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir(\"../\")\n",
    "print(os.getcwd())\n",
    "\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from hypmmm import (\n",
    "    build_model,\n",
    "    centrality,\n",
    "    create_figures,\n",
    "    remove_correction,\n",
    "    utils,\n",
    "    weight_functions,\n",
    ")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "plt.rcParams[\"font.size\"] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example patients definition to input format\n",
    "\n",
    "**Patients 1, 2 and 3:**\n",
    "- Has diseases A, B, and C (i.e. `binmat: [1, 1, 1]`)\n",
    "- Disease progression is A -> B -> C (i.e. `conds_worklist: [0, 1, 2]`)\n",
    "- No duplicates are present (i.e. `idx_worklist: [-1, -1, -1]`)\n",
    "\n",
    "\n",
    "**Patient 4:**\n",
    "- Has diseases A, B, and C (i.e. `binmat: [1, 1, 1]`)\n",
    "- Disease progression is C -> A -> B (i.e. `conds_worklist: [2, 0, 1]`)\n",
    "- No duplicates are present (i.e. `idx_worklist: [-1, -1, -1]`)\n",
    "\n",
    "\n",
    "**Patient 5:**\n",
    "- Has diseases B and C (i.e. `binmat: [0, 1, 1]`)\n",
    "- Disease progression is B -> C (i.e. `conds_worklist: [1, 2, -1]`)\n",
    "- No duplicates are present (i.e. `idx_worklist: [-1, -1, -1]`)\n",
    "\n",
    "\n",
    "**Patient 6:**\n",
    "- Has disease B (i.e. `binmat: [0, 1, 0]`)\n",
    "- No disease progression (just B) (i.e. `conds_worklist: [1, -1, -1]`)\n",
    "- No duplicates are present, and only has one condition (i.e. `idx_worklist: [-2, -1, -1]`)\n",
    "\n",
    "\n",
    "**Patient 7:**\n",
    "- Has disease C (i.e. `binmat: [0, 0, 1]`)\n",
    "- No disease progression (just C) (i.e. `conds_worklist: [2, -1, -1]`)\n",
    "- No duplicates are present, and only has one condition (i.e. `idx_worklist: [-2, -1, -1]`)\n",
    "\n",
    "\n",
    "**Patient 8:**\n",
    "- Has diseases A, B and C (i.e. `binmat: [1, 1, 1]`)\n",
    "- Disease progression is B -> A -> C (i.e. `conds_worklist: [1, 0, 2]`)\n",
    "- No duplicates are present (i.e. `idx_worklist: [-1, -1, -1]`)\n",
    "\n",
    "\n",
    "**Patient 9:**\n",
    "- Has diseases A and B (i.e. `binmat: [1, 1, 0]`)\n",
    "- Disease progression is B -> A (i.e. `conds_worklist: [1, 0, -1]`)\n",
    "- No duplicates are present (i.e. `idx_worklist: [-1, -1, -1]`)\n",
    "\n",
    "\n",
    "**Patient 10:**\n",
    "- Has diseases A and C (i.e. `binmat: [1, 0, 1]`)\n",
    "- Disease progression is A -> C (i.e. `conds_worklist: [0, 2, -1]`)\n",
    "- No duplicates are present (i.e. `idx_worklist: [-1, -1, -1]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_diseases = 3\n",
    "colarr = np.asarray(list(string.ascii_uppercase[:n_diseases]), dtype=\"<U24\")\n",
    "\n",
    "# Fictitious trajectory of 'diseases' A, B and C\n",
    "edge_list = [\n",
    "    (\"A\", \"B\", \"C\"),\n",
    "    (\"A\", \"B\", \"C\"),\n",
    "    (\"A\", \"B\", \"C\"),\n",
    "    (\"C\", \"A\", \"B\"),\n",
    "    (\"B\", \"C\"),\n",
    "    (\"B\", \"B\"),\n",
    "    (\"C\", \"C\"),\n",
    "    (\"B\", \"A\", \"C\"),\n",
    "    (\"B\", \"A\"),\n",
    "    (\"A\", \"C\"),\n",
    "]\n",
    "\n",
    "binmat, conds_worklist, idx_worklist = utils.create_initial_worklists(\n",
    "    n_diseases, edge_list\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With or without mortality?\n",
    "\n",
    "\n",
    "\n",
    "Mortality | Short Description | Detail\n",
    ":-:|:-|:-\n",
    "No Mortality | 0 mortality nodes <br /> 0 alive nodes | Nothing to represent progression to death\n",
    "Mortality | 1 mortality node $M$ <br /> 1 alive node $S$ | A single node for death and a single node to represent the individual still alive by the end of the cohort period of analysis (PoA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_prog = -1 * np.ones(binmat.shape[0], dtype=np.int8)  # Ignores fictitious mortality\n",
    "end_type = 0\n",
    "mort_type = None\n",
    "\n",
    "inc_mat, weights, mort_colarr = build_model.compute_weights(\n",
    "    binmat,\n",
    "    conds_worklist,\n",
    "    idx_worklist,\n",
    "    colarr,\n",
    "    \"progression\",\n",
    "    weight_functions.modified_sorensen_dice_coefficient,\n",
    "    end_prog,\n",
    "    dice_type=1,\n",
    "    end_type=end_type,\n",
    "    plot=False,\n",
    "    ret_inc_mat=True,\n",
    "    sort_weights=False,\n",
    ")\n",
    "\n",
    "\n",
    "hyperedge_weights = np.array(weights[0][\"weight\"])\n",
    "hyperedge_titles = np.array(weights[0][\"disease set\"])\n",
    "\n",
    "hyperarc_weights = np.array(weights[1][\"weight\"])\n",
    "progression_titles = np.array(weights[1][\"progression\"])\n",
    "\n",
    "node_weights = np.array(weights[2][\"weight\"])\n",
    "node_titles = np.array(weights[2][\"node\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = build_model.setup_vars(\n",
    "    inc_mat,\n",
    "    n_diseases,\n",
    "    hyperarc_weights,\n",
    "    progression_titles,\n",
    "    node_weights,\n",
    "    mort_type=mort_type,\n",
    ")\n",
    "inc_mat_data, hyperarc_data, node_weights, node_degs, edge_degs = output\n",
    "\n",
    "inc_mat_tail, inc_mat_head = inc_mat_data\n",
    "\n",
    "edge_weights, hyperarc_titles = hyperarc_data\n",
    "\n",
    "node_degree_tail, node_degree_head = node_degs\n",
    "edge_degree_tail, edge_degree_head = edge_degs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = (\n",
    "    (inc_mat_tail, inc_mat_head),\n",
    "    (edge_weights, node_weights),\n",
    "    node_degs,\n",
    "    edge_degree_tail,\n",
    ")\n",
    "\n",
    "node_pagerank = centrality.pagerank_centrality(\n",
    "    inpt,\n",
    "    rep=\"standard\",\n",
    "    typ=\"successor\",\n",
    "    tolerance=1e-10,\n",
    "    max_iterations=1000,\n",
    "    is_irreducible=True,\n",
    "    weight_resultant=False,\n",
    "    random_seed=None,\n",
    "    eps=0.00001,\n",
    ")\n",
    "\n",
    "all_node_sc_evc = pd.DataFrame(\n",
    "    {\n",
    "        \"Disease\": mort_colarr,\n",
    "        \"Successor PageRank\": node_pagerank,\n",
    "    }\n",
    ")\n",
    "\n",
    "succ_order = (\n",
    "    all_node_sc_evc.sort_values(by=\"Successor PageRank\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    "    .Disease\n",
    ")\n",
    "succ_node_sc_evc = (\n",
    "    all_node_sc_evc.sort_values(by=\"Successor PageRank\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    "    .round({\"Successor PageRank\": 3})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = (\n",
    "    (inc_mat_tail, inc_mat_head),\n",
    "    (edge_weights, node_weights),\n",
    "    node_degs,\n",
    "    edge_degree_tail,\n",
    ")\n",
    "\n",
    "node_pagerank = centrality.pagerank_centrality(\n",
    "    inpt,\n",
    "    rep=\"standard\",\n",
    "    typ=\"predecessor\",\n",
    "    tolerance=1e-5,\n",
    "    max_iterations=1_000,\n",
    "    is_irreducible=True,\n",
    "    weight_resultant=True,\n",
    "    random_seed=None,\n",
    ")\n",
    "\n",
    "all_node_pr_evc = pd.DataFrame(\n",
    "    {\"Disease\": mort_colarr, \"Predecessor PageRank\": node_pagerank}\n",
    ")\n",
    "\n",
    "pred_order = (\n",
    "    all_node_pr_evc.sort_values(by=\"Predecessor PageRank\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    "    .Disease\n",
    ")\n",
    "pred_node_pd_evc = (\n",
    "    all_node_pr_evc.sort_values(by=\"Predecessor PageRank\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    "    .round({\"Predecessor PageRank\": 3})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "succ_node_sc_evc.columns = [\"Disease\", \"No Mort Suc PageRank\"]\n",
    "pred_node_pd_evc.columns = [\"Disease\", \"No Mort Pred PageRank\"]\n",
    "no_mort_pagerank = pred_node_pd_evc.merge(succ_node_sc_evc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_figures.pagerank_scatter(\n",
    "    suc_col=no_mort_pagerank[\"No Mort Suc PageRank\"],\n",
    "    pred_col=no_mort_pagerank[\"No Mort Pred PageRank\"],\n",
    "    dis_col=no_mort_pagerank[\"Disease\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mortality Type 1 with Remove PageRank Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example patients definition to input format\n",
    "\n",
    "**Patients 1, 2, 3, 5 and 10:**\n",
    "- Have Mort end nodes\n",
    "\n",
    "**Patient 4, 6, 7, 8, and 9:**\n",
    "- Have Alive end nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_prog = np.array([1, 1, 1, 0, 1, 0, 0, 0, 0, 1], dtype=np.int8)\n",
    "\n",
    "if np.any(end_prog == -1):\n",
    "    mort_type = None\n",
    "    end_type = 0\n",
    "    mort_incl = False\n",
    "else:\n",
    "    mort_type = 1\n",
    "    end_type = mort_type\n",
    "    mort_incl = True\n",
    "\n",
    "(\n",
    "    remove_cor_df,\n",
    "    mort1_inc_mat_tail,\n",
    "    mort1_inc_mat_head,\n",
    "    mort1_hyperarc_weights,\n",
    "    mort1_node_weights,\n",
    "    mort1_hyperarc_titles,\n",
    ") = remove_correction.calc_remove_pagerank(\n",
    "    n_diseases,\n",
    "    binmat,\n",
    "    conds_worklist,\n",
    "    idx_worklist,\n",
    "    contribution_type=\"progression\",\n",
    "    weight_function=weight_functions.modified_sorensen_dice_coefficient,\n",
    "    complete_denom=1,\n",
    "    end_prog=end_prog,\n",
    "    plot=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot for Corrected PageRank\n",
    "create_figures.pagerank_scatter(\n",
    "    suc_col=remove_cor_df[\"Corrected Suc PageRank\"],\n",
    "    pred_col=remove_cor_df[\"Corrected Pred PageRank\"],\n",
    "    dis_col=remove_cor_df[\"Disease\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct incidence matrix for undirected representation of directed hypergraph\n",
    "incidence_matrix = np.concatenate([mort1_inc_mat_tail, mort1_inc_mat_head], axis=0)\n",
    "incidence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mort1_node_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperarc_centrality = centrality.eigenvector_centrality(\n",
    "    incidence_matrix,\n",
    "    mort1_hyperarc_weights,\n",
    "    mort1_node_weights,\n",
    "    rep=\"dual\",\n",
    "    tolerance=1e-6,\n",
    "    max_iterations=1000,\n",
    "    weight_resultant=True,\n",
    "    random_seed=None,\n",
    ")\n",
    "\n",
    "n_conds = n_diseases * [2] + [\n",
    "    len(d.split(\",\")) + 1 for d in mort1_hyperarc_titles[n_diseases:]\n",
    "]\n",
    "\n",
    "hyperarc_evc = pd.DataFrame(\n",
    "    {\n",
    "        \"Disease\": mort1_hyperarc_titles,\n",
    "        \"Degree\": n_conds,\n",
    "        \"Eigenvector Centrality\": np.round(hyperarc_centrality, 3),\n",
    "    },\n",
    ")\n",
    "hyperarc_evc.sort_values(by=\"Degree\", ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_forward_prog(disease_set, hyperarc_evc, n, max_degree):\n",
    "    \"\"\"\n",
    "    Given a disease set, generate a tree of likely disease progressions given the hyperarc eigenvector\n",
    "    centrality values. n decides on the number of disease progessions to generate.\n",
    "\n",
    "    Args:\n",
    "        disease_set (str) : Observed disease progression. Must be of format\n",
    "        \"DIS1, DIS2, ..., DISn-1\"\n",
    "\n",
    "        hyperarc_evc (pd.DataFrame) : Dataframe of hyperarc eigenvector centrality values.\n",
    "\n",
    "        n (int) : Number of progressions to return.\n",
    "\n",
    "        max_degree (int) : Maximum degree disease progression to generate.\n",
    "    \"\"\"\n",
    "    pathways = [[] for i in range(n)]\n",
    "    deg = len(disease_set.split(\", \")) + 1\n",
    "    if deg < max_degree:\n",
    "        deg_hyperarc_evc = hyperarc_evc[hyperarc_evc.Degree == deg]\n",
    "        deg_dis = np.array([dis.split(\" -> \")[0] for dis in deg_hyperarc_evc.Disease])\n",
    "        deg_dis_hyperarc_evc = deg_hyperarc_evc.iloc[\n",
    "            np.where(deg_dis == disease_set)\n",
    "        ].sort_values(by=\"Eigenvector Centrality\", ascending=False, axis=0)\n",
    "        deg_progs = list(deg_dis_hyperarc_evc.iloc[:n].Disease)\n",
    "        for i, prog in enumerate(deg_progs):\n",
    "            pathways[i].append(prog)\n",
    "            disease_set = \", \".join(prog.split(\" -> \"))\n",
    "            prog_pathway = generate_forward_prog(\n",
    "                disease_set, hyperarc_evc, 2, max_degree\n",
    "            )\n",
    "            if prog_pathway is not None:\n",
    "                pathways[i].append(prog_pathway)\n",
    "        deg += 1\n",
    "    else:\n",
    "        pathways = None\n",
    "\n",
    "    return pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pathways(progression, hyperarc_evc, n):\n",
    "    \"\"\"\n",
    "    Given a disease progression specified, use the hyperarc eigenvector centrality\n",
    "    ranking of observed disease progressions to generate the observed disease progression\n",
    "    before the specified one.\n",
    "\n",
    "    Args:\n",
    "        progression (str) : Observed disease progression. Must be of format\n",
    "        \"DIS1, DIS2, ..., DISn-1 -> DISn\"\n",
    "\n",
    "        hyperarc_evc (pd.DataFrame) : Dataframe of hyperarc eigenvector centrality values.\n",
    "\n",
    "        n (int) : Number of progressions to return.\n",
    "    \"\"\"\n",
    "    # Extract tail set and tail degree\n",
    "    prog_tail = progression.split(\" -> \")[0].split(\", \")\n",
    "    pathway_progressions = pd.DataFrame()\n",
    "    deg_hyperarc_evc = hyperarc_evc[hyperarc_evc.Degree == len(prog_tail)].sort_values(\n",
    "        by=\"Eigenvector Centrality\", ascending=False, axis=0\n",
    "    )\n",
    "    # Loop over hyperarc centralities.\n",
    "    for i, row in deg_hyperarc_evc.iterrows():\n",
    "        disease_prog, deg, cent = row\n",
    "\n",
    "        # If degree of hyperarc in iteration matches degree of tail set then extract tail and head\n",
    "        # members\n",
    "        diseases_tail = disease_prog.split(\" -> \")[0].split(\", \")\n",
    "        diseases_head = disease_prog.split(\" -> \")[1]\n",
    "        diseases = diseases_tail + [diseases_head]\n",
    "\n",
    "        # Loop over diseases in tail set of progression and only extract hyperarcs which match the tail and\n",
    "        # head sets\n",
    "        for dis in prog_tail:\n",
    "            prog = prog_tail.copy()\n",
    "            prog.remove(dis)\n",
    "            if dis in diseases_head and np.all(np.sort(prog) == np.sort(diseases_tail)):\n",
    "                pathway_progressions = pd.concat(\n",
    "                    [pathway_progressions, pd.DataFrame(row).T], axis=0\n",
    "                )\n",
    "\n",
    "    # Extract n of these pathways and return\n",
    "    print(f\"Found {pathway_progressions.shape[0]} possible pathways...\")\n",
    "    # If there are no pathways there will be no dataframe and so an error will occur\n",
    "    return list(\n",
    "        pathway_progressions.reset_index(drop=True)\n",
    "        .sort_values(by=\"Eigenvector Centrality\", axis=0, ascending=False)\n",
    "        .iloc[:n][\"Disease\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_pathways(progression, hyperarc_evc, n):\n",
    "    \"\"\"\n",
    "    Given an observed disease progression, generate all likely pathways to that progression\n",
    "    using the hyperarc centralities computed.\n",
    "\n",
    "    Args:\n",
    "        progression (str) : Observed disease progression. Must be of format\n",
    "        \"DIS1, DIS2, ..., DISn-1 -> DISn\"\n",
    "\n",
    "        hyperarc_evc (pd.DataFrame) : Dataframe of hyperarc eigenvector centrality values.\n",
    "\n",
    "        n (int) : Number of progressions to return.\n",
    "    \"\"\"\n",
    "    # Extract tail set and tail degree\n",
    "    print(progression)\n",
    "    prog_tail = progression.split(\" -> \")[0].split(\", \")\n",
    "    deg = len(prog_tail)\n",
    "    pathway_progressions = dict()\n",
    "\n",
    "    if deg != 1:\n",
    "        pathways = generate_pathways(progression, hyperarc_evc, n)\n",
    "        pathway_progressions[progression] = pathways\n",
    "        for progression in pathways:\n",
    "            prog_pathways = generate_all_pathways(progression, hyperarc_evc, n)\n",
    "            if prog_pathways == {}:\n",
    "                prog_tail = progression.split(\" -> \")[0]\n",
    "                pathway_progressions[progression] = [f\"{prog_tail} -> {prog_tail}\"]\n",
    "            else:\n",
    "                pathway_progressions[progression] = list(prog_pathways.values())\n",
    "\n",
    "    return pathway_progressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progression = \"A, B, C -> MORT\"\n",
    "test = generate_all_pathways(progression, hyperarc_evc, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the top n (3) centralities for each degree type\n",
    "top_n = 3\n",
    "top_progressions = pd.DataFrame()\n",
    "max_d = 4\n",
    "for deg in range(1, max_d + 1):\n",
    "    deg_hyperarc_evc = hyperarc_evc[hyperarc_evc.Degree == deg].sort_values(\n",
    "        by=\"Eigenvector Centrality\", ascending=False, axis=0\n",
    "    )\n",
    "    top_progressions = pd.concat(\n",
    "        [top_progressions, deg_hyperarc_evc.iloc[:top_n]], axis=0\n",
    "    )\n",
    "\n",
    "top_progressions.reset_index(drop=True).sort_values(by=\"Degree\", ascending=True, axis=0)\n",
    "top_progressions\n",
    "rank_progressions = top_progressions.copy()\n",
    "rank_progressions.index = (max_d * [i for i in range(top_n)])[\n",
    "    : rank_progressions.shape[0]\n",
    "]\n",
    "rank_progressions.reset_index(inplace=True)\n",
    "\n",
    "rank_progressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_idx_lists = []\n",
    "for deg in range(1, max_d):\n",
    "    deg_dis_progs = rank_progressions[rank_progressions.Degree == deg].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    lst_idx = deg - 1\n",
    "    n_degs = deg_dis_progs.shape[0]\n",
    "    prog_idx_lists.append([[] for i in range(n_degs)])\n",
    "    for deg_dis_prog in deg_dis_progs.iterrows():\n",
    "        i, (idx, dis_prog, dis_deg, eig_cent) = deg_dis_prog\n",
    "        if deg != 1:\n",
    "            prog_tail = dis_prog.split(\" -> \")[0].split(\", \")\n",
    "            prog_head = dis_prog.split(\" -> \")[1]\n",
    "            prog_dis = np.sort(prog_tail + [prog_head])\n",
    "        else:\n",
    "            prog_dis = dis_prog.split(\" -> \")[0]\n",
    "        degabove_dis_progs = rank_progressions[\n",
    "            rank_progressions.Degree == dis_deg + 1\n",
    "        ].Disease\n",
    "\n",
    "        for j, degabove_dis in enumerate(degabove_dis_progs):\n",
    "            degabove_tail = np.sort(degabove_dis.split(\" -> \")[0].split(\", \"))\n",
    "            if np.all(prog_dis == degabove_tail):\n",
    "                prog_idx_lists[lst_idx][i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_figures.dis_prog_paths(rank_progressions, max_d, top_n, prog_idx_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
